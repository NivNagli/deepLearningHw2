{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7eriu5V5HOO"
      },
      "source": [
        "## Installation Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8mMusTg5HOO",
        "outputId": "850eabde-97a8-42b1-c7e3-af0f359616a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: =1.2.0: No such file or directory\n",
            "Requirement already satisfied: torchtext==0.4 in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (2.27.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (1.11.0+cu113)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (1.15.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.4) (4.2.0)\n",
            "Requirement already satisfied: python-arango in /usr/local/lib/python3.7/dist-packages (7.3.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from python-arango) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.7/dist-packages (from python-arango) (57.4.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from python-arango) (1.26.9)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.7/dist-packages (from python-arango) (0.9.1)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.7/dist-packages (from python-arango) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->python-arango) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->python-arango) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->python-arango) (2.0.12)\n",
            "Requirement already satisfied: arangopipe==0.0.70.0.0 in /usr/local/lib/python3.7/dist-packages (0.0.70.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: PyYAML==5.1.1 in /usr/local/lib/python3.7/dist-packages (5.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch<=1.2.0\n",
        "!pip install torchtext==0.4\n",
        "!pip install python-arango\n",
        "!pip install arangopipe==0.0.70.0.0\n",
        "!pip install pandas PyYAML==5.1.1\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2735I-L5HOP",
        "outputId": "4d3850b8-58b0-4199-a14d-323986d5a74c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120000lines [00:09, 12314.05lines/s]\n",
            "120000lines [00:16, 7171.95lines/s]\n",
            "7600lines [00:01, 7141.50lines/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.datasets import text_classification\n",
        "NGRAMS = 2\n",
        "import os\n",
        "if not os.path.isdir('./.data'):\n",
        "\tos.mkdir('./.data')\n",
        "train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](\n",
        "    root='./.data', ngrams=NGRAMS, vocab=None)\n",
        "BATCH_SIZE = 16\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8pfzUMBl5HOP"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class TextSentiment(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "        \n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uwm8Ta_65HOP"
      },
      "source": [
        "Initiate an instance\n",
        "--------------------\n",
        "\n",
        "The AG_NEWS dataset has four labels and therefore the number of classes\n",
        "is four.\n",
        "\n",
        "::\n",
        "\n",
        "   1 : World\n",
        "   2 : Sports\n",
        "   3 : Business\n",
        "   4 : Sci/Tec\n",
        "\n",
        "The vocab size is equal to the length of vocab (including single word\n",
        "and ngrams). The number of classes is equal to the number of labels,\n",
        "which is four in AG_NEWS case.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rpcuhy5D5HOP"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
        "EMBED_DIM = 32\n",
        "NUN_CLASS = len(train_dataset.get_labels())\n",
        "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y1u0IkPZ5HOP"
      },
      "outputs": [],
      "source": [
        "def generate_batch(batch):\n",
        "    label = torch.tensor([entry[0] for entry in batch])\n",
        "    text = [entry[1] for entry in batch]\n",
        "    offsets = [0] + [len(entry) for entry in text]\n",
        "    # torch.Tensor.cumsum returns the cumulative sum\n",
        "    # of elements in the dimension dim.\n",
        "    # torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0)\n",
        "    \n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text = torch.cat(text)\n",
        "    return text, offsets, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3GPSyEV5HOP"
      },
      "source": [
        "Define functions to train the model and evaluate results.\n",
        "---------------------------------------------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj4ujCef5HOP"
      },
      "source": [
        "`torch.utils.data.DataLoader <https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader>`__\n",
        "is recommended for PyTorch users, and it makes data loading in parallel\n",
        "easily (a tutorial is\n",
        "`here <https://pytorch.org/tutorials/beginner/data_loading_tutorial.html>`__).\n",
        "We use ``DataLoader`` here to load AG_NEWS datasets and send it to the\n",
        "model for training/validation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PyyfZj2l5HOP"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch)\n",
        "    for i, (text, offsets, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        output = model(text, offsets)\n",
        "        loss = criterion(output, cls)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "    \n",
        "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
        "\n",
        "def test(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
        "    for text, offsets, cls in data:\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text, offsets)\n",
        "            loss = criterion(output, cls)\n",
        "            loss += loss.item()\n",
        "            acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    return loss / len(data_), acc / len(data_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1ENu-Su5HOP"
      },
      "source": [
        "Split the dataset and run the model\n",
        "-----------------------------------\n",
        "\n",
        "Since the original AG_NEWS has no valid dataset, we split the training\n",
        "dataset into train/valid sets with a split ratio of 0.95 (train) and\n",
        "0.05 (valid). Here we use\n",
        "`torch.utils.data.dataset.random_split <https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split>`__\n",
        "function in PyTorch core library.\n",
        "\n",
        "`CrossEntropyLoss <https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss>`__\n",
        "criterion combines nn.LogSoftmax() and nn.NLLLoss() in a single class.\n",
        "It is useful when training a classification problem with C classes.\n",
        "`SGD <https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html>`__\n",
        "implements stochastic gradient descent method as optimizer. The initial\n",
        "learning rate is set to 4.0.\n",
        "`StepLR <https://pytorch.org/docs/master/_modules/torch/optim/lr_scheduler.html#StepLR>`__\n",
        "is used here to adjust the learning rate through epochs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3in0Ouw5HOP",
        "outputId": "0d3dc08d-6e25-4c26-f86c-209382329b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 23 seconds\n",
            "\tLoss: 0.0261(train)\t|\tAcc: 84.8%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 90.0%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 16 seconds\n",
            "\tLoss: 0.0119(train)\t|\tAcc: 93.6%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 90.3%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 16 seconds\n",
            "\tLoss: 0.0069(train)\t|\tAcc: 96.4%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 90.2%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 17 seconds\n",
            "\tLoss: 0.0039(train)\t|\tAcc: 98.1%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 91.3%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 16 seconds\n",
            "\tLoss: 0.0022(train)\t|\tAcc: 99.0%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 91.1%(valid)\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from torch.utils.data.dataset import random_split\n",
        "N_EPOCHS = 5\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "train_len = int(len(train_dataset) * 0.95)\n",
        "sub_train_, sub_valid_ = \\\n",
        "    random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(sub_train_)\n",
        "    valid_loss, valid_acc = test(sub_valid_)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBK_oNCA5HOP"
      },
      "source": [
        "Evaluate the model with test dataset\n",
        "------------------------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Ya3qHn5HOP",
        "outputId": "ff8dea2f-32d3-4192-d813-c20f8806eac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset...\n",
            "\tLoss: 0.0002(test)\t|\tAcc: 89.7%(test)\n"
          ]
        }
      ],
      "source": [
        "print('Checking the results of test dataset...')\n",
        "test_loss, test_acc = test(test_dataset)\n",
        "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfdb1aoj5HOQ"
      },
      "source": [
        "Test on a random news\n",
        "---------------------\n",
        "\n",
        "Use the best model so far and test a golf news. The label information is\n",
        "available\n",
        "`here <https://pytorch.org/text/datasets.html?highlight=ag_news#torchtext.datasets.AG_NEWS>`__.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql5PlREV5HOQ",
        "outputId": "f3253a30-e476-4ea2-f3e9-f9a38793ef52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a Sports news\n",
            "This is a Sci/Tec news\n",
            "This is a Business news\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from torchtext.data.utils import ngrams_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "ag_news_label = {1 : \"World\",\n",
        "                 2 : \"Sports\",\n",
        "                 3 : \"Business\",\n",
        "                 4 : \"Sci/Tec\"}\n",
        "\n",
        "def predict(text, model, vocab, ngrams):\n",
        "    tokenizer = get_tokenizer(\"basic_english\")\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor([vocab[token]\n",
        "                            for token in ngrams_iterator(tokenizer(text), ngrams)])\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "\n",
        "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
        "    enduring the season’s worst weather conditions on Sunday at The \\\n",
        "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "    considering the wind and the rain was a respectable showing. \\\n",
        "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "    was another story. With temperatures in the mid-80s and hardly any \\\n",
        "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "    was even more impressive considering he’d never played the \\\n",
        "    front nine at TPC Southwind.\"\n",
        "\n",
        "ex_text_str2 = \"Cerithiella superba is a species of very small sea snail, a marine gastropod mollusk in the family Newtoniellidae. This species is known from European waters. It was described by Thiele, 1912.\"\n",
        "\n",
        "ex_test_str3 = \"A couple is suing their only son and his wife for not giving them a grandchild after six years of marriage.\"\n",
        "\n",
        "vocab = train_dataset.get_vocab()\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, model, vocab, 2)])\n",
        "\n",
        "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str2, model, vocab, 2)])\n",
        "\n",
        "print(\"This is a %s news\" %ag_news_label[predict(ex_test_str3, model, vocab, 2)])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Arangopipe_with_Pytorch_Example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
